document,questions
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What do instances of ""autocast"" serve as?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What are context managers or decorators?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is chosen by autocast to improve performance while maintaining accuracy?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","When entering an autocast-enabled region, what type of Tensors may be?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should you not call on your model(s) or inputs when using autocast?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What should ""autocast"" wrap only the forward pass(s) of your network?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What are not recommended under autocast?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What type of ops run in the same type that autocast used for corresponding forward ops?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Creates model and optimizer in default precision model?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does optimizer do for input?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the target in data?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Enables autocasting for the forward pass (model + loss) with what function?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What does loss = loss_fn(output, target) do?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",Exits the context manager before what?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does optimizer.step() do?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What can be used as a CUDA example?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What can also be used as a decorator?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What can be used on the ""forward"" method of your model?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","@autocast() def forward(self, input): Floating-point Tensors produced in an autocast-enabled region may be what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What may an autocast-enabled region be?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What may cause type mismatch errors?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","When casting the Tensor(s) produced in the autocast region back to ""float32""?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does autocast region back to if desired?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is cast a no-op and incurs no additional overhead?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Creates some tensors in default dtype (here assumed to be float32)?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","a_float32 = torch.rand((8, 8), device=""cuda"") what is b_float 32 = torch?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is on autocast's list of ops that should run in float16?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should run in float16?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","Inputs are float32, but the op runs in what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does f_float16 mean?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What does torch.mm(a_float32, b_float 32) handle?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What does torch.mm(d_float32, e_float16) do after exiting autocast?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the name of the program that creates model and optimizer in default precision?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the default precision model?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",what is the target in data: for input?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","For input, target in data: optimizer.zero_grad() # Runs the forward pass with what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What does torch.autocast(device_type=""cpu"", dtype=torch.bfloat16) do?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is loss.backward() optimizer.step()?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does optimizer.step() CPU Inference Example: # Creates model in default precision model = Net().eval()?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Runs the forward pass with what?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",output = model(input) CPU Inference Example
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What is output = model(input) CPU Inference Example with Jit Trace: class TestModel(nn.Module): def __init__(self, input_size, num_classes): super(TestModel, self)?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What is super(TestModel, self).__init__() self.fc1 = nn.Linear(input_size, num_classes)?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What does return self.fc1(x) input_size = 2 num_classes = 2 model = TestModel(input_size, num clases)?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","For now, we suggest to disable what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","# For now, we suggest to disable what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",https://github.com/pytorch/issues/75956 torch?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What is model = torch.jit.trace(model, torch.randn(1, input_size))?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",Models Run for what type of mismatch?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What are type mismatch errors in an autocast-enabled region?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",How can subregions be nested in autocast enabled regions?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What can be useful if you want to force a subregion to run in a particular ""dtype""?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What gives you explicit control over the execution type?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should inputs from the surrounding region be cast to before use?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Creates some tensors in default dtype (here assumed to be what?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","a_float32 = torch.rand((8, 8), device=""cuda"") what is a float32?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",b_float 32 is what?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",with autocast(): what is the name of the device?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does e_float16 do?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does autocast(enabled=False) call to ensure float32 execution?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# Calls e_float16.float() to ensure float32 execution?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# No manual casts are required when re-entering the autocast-enabled region?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",# torch.mm runs in float16 and produces what output?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the autocast state?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What must be invoked if you want it enabled in a new thread?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What must be invoked in a new thread?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What affects ""torch.nn.DataParallel"" when used with more than one GPU per process?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should be enabled in the device?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should autocasting be enabled?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What should be enabled in the region?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the default?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the default value of the class torch.cuda.amp.autocast?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What does cache_enabled do?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is a helper decorator for forward methods of custom autograd functions?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",See the example page for more detail.
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","default=None) -- If ""forward"" runs in an autocast-enabled region, what casts incoming floating-point CUDA Tensors to the target dtype?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What happens if the decorated ""forward"" is called outside of an autocast-enabled ops?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What is a no-op if the decorated ""forward"" is called outside of an autocast-enabled region?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed",What is the helper decorator for backward methods of custom autograd functions?
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","""backward"" executes with the same autocast state as what?"
"class torch.autocast(device_type, dtype=None, enabled=True, cache_enabled=None)

   Instances of ""autocast"" serve as context managers or decorators
   that allow regions of your script to run in mixed","What is equivalent to ""torch.cpu.amp.autocast(""cpu"", args...)?"""
